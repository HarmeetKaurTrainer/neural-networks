# neural-networks

# Gradient Descent
Please refer the link to view the Gradient Descent implemented with a Loss Function, Error, Output.

https://nbviewer.jupyter.org/github/ksranjith786/neural-networks/blob/master/optimizers/GradientDescent.ipynb

# Activation Functions

## Sigmoid
## TanH
## ReLU
## Leaky ReLU
## SeLU
